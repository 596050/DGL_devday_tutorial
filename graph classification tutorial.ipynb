{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Classification with DGL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we demonstrate how to use DGL to finish graph classification tasks. The dataset we use here is Tox21, a public database measuring toxicity of compounds.  The dataset contains qualitative toxicity measurements for 8014 compounds on 12 different targets, including nuclear receptors and stress response pathways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data.chem import Tox21\n",
    "from dgl import model_zoo\n",
    "from dgl.data.utils import split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw,MolFromSmiles, MolToSmiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would take about one minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously saved dgl graphs...\n"
     ]
    }
   ],
   "source": [
    "dataset = Tox21()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = split_dataset(dataset, [0.8, 0.2], shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each target label in a binary label. A common issue for multi-task prediction is that some datapoints are not labeled for all tasks. This is also the case for Tox21. In data pre-processing, we set non-existing labels to be 0 and corresponding mask value to be 0 too. The label below means NR-AhR has positive labels, and NR-Aromatase and NR-ER's labels are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']\n",
      "CCOc1ccc2nc(S(N)(=O)=O)sc2c1\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "smile, graph, label, mask = dataset[0]\n",
    "print(dataset.task_names)\n",
    "print(smile)\n",
    "print(label)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=600x200 at 0x7FEBA9174160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Draw.MolsToGridImage([MolFromSmiles(smile)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each atom can be considered as a node in graph, and the bond between them are the edges. We use [`CanonicalAtomFeaturizer`](https://docs.dgl.ai/generated/dgl.data.chem.CanonicalAtomFeaturizer.html#dgl.data.chem.CanonicalAtomFeaturizer), a fingerprint method to create feature for each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.ndata['h']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DGL could batch multiple small graphs together to accelerate the computation. Detail of batching can be found [here](https://docs.dgl.ai/tutorials/basics/4_batch.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/batch/batch.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_molgraphs_for_classification(data):\n",
    "    \"\"\"Batching a list of datapoints for dataloader in classification tasks.\"\"\"\n",
    "    smiles, graphs, labels, mask = map(list, zip(*data))\n",
    "    bg = dgl.batch(graphs)\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    mask = torch.stack(mask, dim=0)\n",
    "    return smiles, bg, labels, mask\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size= 1024,\n",
    "                          collate_fn=collate_molgraphs_for_classification)\n",
    "val_loader = DataLoader(valset, batch_size= len(valset),\n",
    "                        collate_fn=collate_molgraphs_for_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a two layer Graph Convolutional Network to classify the graphs. Detailed source code can be found [here](https://github.com/dmlc/dgl/blob/master/python/dgl/model_zoo/chem/classifiers.py#L111)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNClassifier(\n",
      "  (gnn_layers): ModuleList(\n",
      "    (0): GCNLayer(\n",
      "      (graph_conv): GraphConv(in=74, out=128, normalization=False, activation=<function relu at 0x7feb2f33dae8>)\n",
      "      (dropout): Dropout(p=0.0)\n",
      "      (res_connection): Linear(in_features=74, out_features=128, bias=True)\n",
      "      (bn_layer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): GCNLayer(\n",
      "      (graph_conv): GraphConv(in=128, out=64, normalization=False, activation=<function relu at 0x7feb2f33dae8>)\n",
      "      (dropout): Dropout(p=0.0)\n",
      "      (res_connection): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (bn_layer): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (weighted_sum_readout): WeightAndSum(\n",
      "    (atom_weighting): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (soft_classifier): MLPBinaryClassifier(\n",
      "    (predict): Sequential(\n",
      "      (0): Dropout(p=0.0)\n",
      "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): Linear(in_features=128, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = model_zoo.chem.GCNClassifier(in_feats=74, gcn_hidden_feats=[128, 64], n_tasks=12).cuda()\n",
    "loss_criterion = BCEWithLogitsLoss(reduction='none')\n",
    "optimizer = Adam(model.parameters())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5876147150993347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:01<01:01,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.558411717414856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:01<00:49,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5425251722335815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:02<00:40,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5271397829055786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:02<00:34,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5093251466751099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:03<00:30,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4875337481498718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:03<00:27,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4610597491264343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:04<00:25,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4311479926109314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:04<00:23,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.39738982915878296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:05<00:22,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3623153567314148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:05<00:21,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.32660916447639465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:06<00:20,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2927025854587555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:06<00:19,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.26108428835868835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:07<00:18,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.23346415162086487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:07<00:18,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.21096891164779663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:08<00:17,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1922415941953659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:08<00:16,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.17746353149414062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:09<00:16,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16814391314983368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:09<00:16,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15853887796401978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:10<00:16,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.15198522806167603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:10<00:15,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.14573067426681519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:11<00:15,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.14299198985099792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:11<00:14,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13752280175685883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:12<00:14,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1353558599948883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:12<00:13,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.13188473880290985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:13<00:12,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12855902314186096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:14<00:12,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12634530663490295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:14<00:11,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12337897717952728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [00:15<00:11,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12214009463787079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [00:15<00:10,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.11959465593099594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:16<00:10,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.11824457347393036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:16<00:09,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.11686988919973373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:17<00:09,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.11635354161262512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:17<00:08,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.12135326862335205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [00:18<00:07,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.11697719991207123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:18<00:08,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1135300025343895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [00:19<00:07,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.11862069368362427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [00:19<00:06,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.11016317456960678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [00:20<00:06,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.10646724700927734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [00:20<00:05,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.10522463172674179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [00:21<00:05,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.10247699916362762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [00:21<00:04,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.10324057191610336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [00:22<00:03,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.10076790302991867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [00:22<00:03,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.09709861129522324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [00:23<00:02,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.09726320207118988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [00:23<00:02,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.09650824964046478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [00:24<00:01,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.09565724432468414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [00:24<00:01,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.09427398443222046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [00:25<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.09360237419605255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [00:25<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.09596117585897446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:26<00:00,  1.92it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "model.train()\n",
    "for i in tqdm(range(epochs)):\n",
    "    for batch_id, batch_data in enumerate(train_loader):\n",
    "        smiles, bg, labels, mask = batch_data\n",
    "        atom_feats = bg.ndata.pop('h')\n",
    "        atom_feats, labels, mask = atom_feats.to('cuda'), \\\n",
    "                                   labels.to('cuda'), \\\n",
    "                                   mask.to('cuda')\n",
    "        logits = model(bg, atom_feats)\n",
    "        # Mask non-existing labels\n",
    "        loss = (loss_criterion(logits, labels) * (mask != 0).float()).mean()\n",
    "        if batch_id % 20 == 0:\n",
    "            tqdm.write(\"Loss: {}\".format(loss.item()))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9320, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_id, batch_data in enumerate(tqdm(val_loader)):\n",
    "        smiles, bg, labels, mask = batch_data\n",
    "        atom_feats = bg.ndata.pop('h')\n",
    "        atom_feats, labels, mask = atom_feats.to('cuda'), \\\n",
    "                                   labels.to('cuda'), \\\n",
    "                                   mask.to('cuda')\n",
    "        logits = model(bg, atom_feats)\n",
    "        accuracy_overall_tasks = (((logits>0)==labels.byte()).float()*mask).sum()/mask.sum()\n",
    "        print(accuracy_overall_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We acheived a pretty high accuracy. However, this dataset's labels are imbalanced, which means most labels could be negative. Therefore it would be unfair to evaluate result with accuracy score. A more detailed analysis of this task could be found at our [model zoo](https://github.com/dmlc/dgl/tree/master/examples/pytorch/model_zoo/chem/property_prediction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_miniconda3-latest)",
   "language": "python",
   "name": "conda_miniconda3-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
