{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Classification with DGL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we demonstrate how to use DGL to finish graph classification tasks. The dataset we use here is Tox21, a public database measuring toxicity of compounds.  The dataset contains qualitative toxicity measurements for 8014 compounds on 12 different targets, including nuclear receptors and stress response pathways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl.data.chem import Tox21\n",
    "from dgl import model_zoo\n",
    "from dgl.data.utils import split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw,MolFromSmiles, MolToSmiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would take about one minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously saved dgl graphs...\n"
     ]
    }
   ],
   "source": [
    "dataset = Tox21()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset into train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = split_dataset(dataset, [0.8, 0.2], shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each target label in a binary label. A common issue for multi-task prediction is that some datapoints are not labeled for all tasks. This is also the case for Tox21. In data pre-processing, we set non-existing labels to be 0 and corresponding mask value to be 0 too. The label below means NR-AhR has positive labels, and NR-Aromatase and NR-ER's labels are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']\n",
      "CCOc1ccc2nc(S(N)(=O)=O)sc2c1\n",
      "tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
      "tensor([1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "smile, graph, label, mask = dataset[0]\n",
    "print(dataset.task_names)\n",
    "print(smile)\n",
    "print(label)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=600x200 at 0x7FF2BC283A90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Draw.MolsToGridImage([MolFromSmiles(smile)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each atom can be considered as a node in graph, and the bond between them are the edges. We use [`CanonicalAtomFeaturizer`](https://docs.dgl.ai/generated/dgl.data.chem.CanonicalAtomFeaturizer.html#dgl.data.chem.CanonicalAtomFeaturizer), a fingerprint method to create feature for each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.ndata['h']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DGL could batch multiple small graphs together to accelerate the computation. Detail of batching can be found [here](https://docs.dgl.ai/tutorials/basics/4_batch.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3.us-east-2.amazonaws.com/dgl.ai/tutorial/batch/batch.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_molgraphs_for_classification(data):\n",
    "    \"\"\"Batching a list of datapoints for dataloader in classification tasks.\"\"\"\n",
    "    smiles, graphs, labels, mask = map(list, zip(*data))\n",
    "    bg = dgl.batch(graphs)\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    mask = torch.stack(mask, dim=0)\n",
    "    return smiles, bg, labels, mask\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size= 1024,\n",
    "                          collate_fn=collate_molgraphs_for_classification)\n",
    "val_loader = DataLoader(valset, batch_size= len(valset),\n",
    "                        collate_fn=collate_molgraphs_for_classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a two layer Graph Convolutional Network to classify the graphs. Detailed source code can be found [here](https://github.com/dmlc/dgl/blob/master/python/dgl/model_zoo/chem/classifiers.py#L111)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNClassifier(\n",
      "  (gnn_layers): ModuleList(\n",
      "    (0): GCNLayer(\n",
      "      (graph_conv): GraphConv(in=74, out=128, normalization=False, activation=<function relu at 0x7ff23f3af510>)\n",
      "      (dropout): Dropout(p=0.0)\n",
      "      (res_connection): Linear(in_features=74, out_features=128, bias=True)\n",
      "      (bn_layer): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): GCNLayer(\n",
      "      (graph_conv): GraphConv(in=128, out=64, normalization=False, activation=<function relu at 0x7ff23f3af510>)\n",
      "      (dropout): Dropout(p=0.0)\n",
      "      (res_connection): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (bn_layer): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (weighted_sum_readout): WeightAndSum(\n",
      "    (atom_weighting): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (soft_classifier): MLPBinaryClassifier(\n",
      "    (predict): Sequential(\n",
      "      (0): Dropout(p=0.0)\n",
      "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (4): Linear(in_features=128, out_features=12, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = model_zoo.chem.GCNClassifier(in_feats=74, gcn_hidden_feats=[128, 64], n_tasks=12).cuda()\n",
    "loss_criterion = BCEWithLogitsLoss(reduction='none')\n",
    "optimizer = Adam(model.parameters())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.039240747690200806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:00<00:37,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.04174252599477768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:01<00:36,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.03991314023733139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:02<00:35,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.03849509358406067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:03<00:34,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.03620683774352074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:04<00:38,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.03446788713335991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:04<00:36,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.034364115446805954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:05<00:34,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.032457493245601654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:06<00:33,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.03503230959177017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:07<00:32,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.031008627265691757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:07<00:31,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.035214293748140335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:08<00:30,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.031359586864709854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:09<00:30,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.038301095366477966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:10<00:29,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.03370219096541405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:11<00:27,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.03406341001391411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:11<00:26,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.032088786363601685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:12<00:26,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.03040865622460842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:13<00:24,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.029525702819228172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:14<00:23,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.027573686093091965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:14<00:23,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.027876494452357292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:15<00:22,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.02600916475057602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:16<00:21,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.027585333213210106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:17<00:20,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.025417745113372803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:17<00:20,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0258383359760046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:18<00:19,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0246858112514019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:19<00:19,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.024637766182422638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:20<00:18,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.024306878447532654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:20<00:17,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.023209180682897568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [00:21<00:18,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.022858021780848503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [00:22<00:17,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.02225784957408905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:23<00:15,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0224414374679327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:24<00:14,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.02055797539651394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:24<00:13,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.020824545994400978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:25<00:13,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.020850878208875656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [00:26<00:12,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.02198857069015503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [00:27<00:11,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.019175907596945763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [00:27<00:10,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.022818949073553085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [00:28<00:09,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.021116113290190697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [00:29<00:08,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.02645183354616165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [00:30<00:07,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.023870721459388733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [00:30<00:07,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.02198125049471855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [00:31<00:06,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.024205923080444336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [00:32<00:05,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.023719295859336853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [00:32<00:05,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.022897925227880478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [00:33<00:04,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.019991744309663773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [00:34<00:03,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.018998239189386368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [00:35<00:02,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.018907755613327026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [00:35<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.019363436847925186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [00:36<00:01,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.016610924154520035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [00:37<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.016279257833957672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:38<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "model.train()\n",
    "for i in tqdm(range(epochs)):\n",
    "    for batch_id, batch_data in enumerate(train_loader):\n",
    "        smiles, bg, labels, mask = batch_data\n",
    "        atom_feats = bg.ndata.pop('h')\n",
    "        atom_feats, labels, mask = atom_feats.to('cuda'), \\\n",
    "                                   labels.to('cuda'), \\\n",
    "                                   mask.to('cuda')\n",
    "        logits = model(bg, atom_feats)\n",
    "        # Mask non-existing labels\n",
    "        loss = (loss_criterion(logits, labels) * (mask != 0).float()).mean()\n",
    "        if batch_id % 20 == 0:\n",
    "            tqdm.write(\"Loss: {}\".format(loss.item()))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dgl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-81455db2d987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0msmiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0matom_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-3112fbbcd4cc>\u001b[0m in \u001b[0;36mcollate_molgraphs_for_classification\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Batching a list of datapoints for dataloader in classification tasks.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msmiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dgl' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_id, batch_data in enumerate(tqdm(val_loader)):\n",
    "        smiles, bg, labels, mask = batch_data\n",
    "        atom_feats = bg.ndata.pop('h')\n",
    "        atom_feats, labels, mask = atom_feats.to('cuda'), \\\n",
    "                                   labels.to('cuda'), \\\n",
    "                                   mask.to('cuda')\n",
    "        logits = model(bg, atom_feats)\n",
    "        accuracy_overall_tasks = (((logits>0)==labels.byte()).float()*mask).sum()/mask.sum()\n",
    "        print(accuracy_overall_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We acheived a pretty high accuracy. However, this dataset's labels are imbalanced, which means most labels could be negative. Therefore it would be unfair to evaluate result with accuracy score. A more detailed analysis of this task could be found at our [model zoo](https://github.com/dmlc/dgl/tree/master/examples/pytorch/model_zoo/chem/property_prediction)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_miniconda3-latest)",
   "language": "python",
   "name": "conda_miniconda3-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
